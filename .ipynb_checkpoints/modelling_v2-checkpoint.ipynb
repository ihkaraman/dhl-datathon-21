{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trials\n",
    "    - sum of past data\n",
    "    - average of past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IsmailKaraman\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "order_df = pd.read_csv('data/order_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28656570, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_week</th>\n",
       "      <th>material_num</th>\n",
       "      <th>customer_num</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_sum2</th>\n",
       "      <th>order_sum3</th>\n",
       "      <th>order_sum4</th>\n",
       "      <th>order_sum5</th>\n",
       "      <th>order_sum7</th>\n",
       "      <th>order_sum10</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_sum7</th>\n",
       "      <th>prod_sum10</th>\n",
       "      <th>prod_sum14</th>\n",
       "      <th>whole_sum2</th>\n",
       "      <th>whole_sum3</th>\n",
       "      <th>whole_sum4</th>\n",
       "      <th>whole_sum5</th>\n",
       "      <th>whole_sum7</th>\n",
       "      <th>whole_sum10</th>\n",
       "      <th>whole_sum14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10140</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10142</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10143</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10158</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_week material_num customer_num  order_amount  order_sum2  order_sum3  \\\n",
       "0           1        91704       M10125             2           0           0   \n",
       "1           1        91704       M10140            21           0           0   \n",
       "2           1        91704       M10142            13           0           0   \n",
       "3           1        91704       M10143            12           0           0   \n",
       "4           1        91704       M10158             4           0           0   \n",
       "\n",
       "   order_sum4  order_sum5  order_sum7  order_sum10  ...  prod_sum7  \\\n",
       "0           0           0           0            0  ...          0   \n",
       "1           0           0           0            0  ...          0   \n",
       "2           0           0           0            0  ...          0   \n",
       "3           0           0           0            0  ...          0   \n",
       "4           0           0           0            0  ...          0   \n",
       "\n",
       "   prod_sum10  prod_sum14  whole_sum2  whole_sum3  whole_sum4  whole_sum5  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   whole_sum7  whole_sum10  whole_sum14  \n",
       "0           0            0            0  \n",
       "1           0            0            0  \n",
       "2           0            0            0  \n",
       "3           0            0            0  \n",
       "4           0            0            0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_week       int64\n",
       "material_num    object\n",
       "customer_num    object\n",
       "order_amount     int64\n",
       "order_sum2       int64\n",
       "order_sum3       int64\n",
       "order_sum4       int64\n",
       "order_sum5       int64\n",
       "order_sum7       int64\n",
       "order_sum10      int64\n",
       "order_sum14      int64\n",
       "cust_sum2        int64\n",
       "cust_sum3        int64\n",
       "cust_sum4        int64\n",
       "cust_sum5        int64\n",
       "cust_sum7        int64\n",
       "cust_sum10       int64\n",
       "cust_sum14       int64\n",
       "prod_sum2        int64\n",
       "prod_sum3        int64\n",
       "prod_sum4        int64\n",
       "prod_sum5        int64\n",
       "prod_sum7        int64\n",
       "prod_sum10       int64\n",
       "prod_sum14       int64\n",
       "whole_sum2       int64\n",
       "whole_sum3       int64\n",
       "whole_sum4       int64\n",
       "whole_sum5       int64\n",
       "whole_sum7       int64\n",
       "whole_sum10      int64\n",
       "whole_sum14      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates20 = pd.DataFrame(pd.date_range(start='01-01-2020', end='31-12-2020'), columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/3925827490.py:3: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  currency_20['order_week'] = currency_20['date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "currency_20 = pd.read_csv('data/currency_20.csv', parse_dates=['date'])\n",
    "currency_20.dropna(inplace=True)\n",
    "currency_20['order_week'] = currency_20['date'].dt.week\n",
    "\n",
    "for curr in ['EUR', 'USD']:\n",
    "    for operator in ['min', 'max', 'avg', 'std']:\n",
    "        currency_20[curr + '_' + operator] = currency_20[curr]\n",
    "        \n",
    "currency_20 = currency_20.groupby('order_week').agg({'EUR_min':'min', 'EUR_max':'max', 'EUR_avg':'mean', 'EUR_std':'std', \n",
    "                                               'USD_min':'min', 'USD_max':'max', 'USD_avg':'mean', 'USD_std':'std'}).reset_index()    \n",
    "\n",
    "currency_20['USD_diff_1'] = currency_20['USD_avg'].diff(1)\n",
    "currency_20['USD_diff_2'] = currency_20['USD_avg'].diff(2)\n",
    "currency_20['USD_diff_3'] = currency_20['USD_avg'].diff(3)\n",
    "currency_20['USD_diff_5'] = currency_20['USD_avg'].diff(5)\n",
    "currency_20['USD_diff_7'] = currency_20['USD_avg'].diff(7)\n",
    "currency_20['USD_diff_14'] = currency_20['USD_avg'].diff(14)\n",
    "\n",
    "currency_20['EUR_diff_1'] = currency_20['EUR_avg'].diff(1)\n",
    "currency_20['EUR_diff_2'] = currency_20['EUR_avg'].diff(2)\n",
    "currency_20['EUR_diff_3'] = currency_20['EUR_avg'].diff(3)\n",
    "currency_20['EUR_diff_5'] = currency_20['EUR_avg'].diff(5)\n",
    "currency_20['EUR_diff_7'] = currency_20['EUR_avg'].diff(7)\n",
    "currency_20['EUR_diff_14'] = currency_20['EUR_avg'].diff(14)\n",
    "currency_20.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/1395646822.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  holidays_20['order_week'] = holidays_20['date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "holidays_20 = pd.read_excel('data/holidays_20.xlsx', parse_dates=['date'])\n",
    "holidays_20 = pd.merge(dates20, holidays_20, on=['date'], how='left')\n",
    "holidays_20.fillna(1.0, inplace=True)\n",
    "holidays_20['order_week'] = holidays_20['date'].dt.week\n",
    "holidays_20 = holidays_20.groupby('order_week')['workday'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/3738567944.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  tufe_20['order_week'] = tufe_20['tufe_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "tufe_20 = pd.read_excel('data/tufe_20.xlsx', parse_dates=['date'])\n",
    "tufe_20.sort_values(by='date', inplace=True)\n",
    "tufe_20['yearly_diff'] = tufe_20['yearly'].diff()\n",
    "tufe_20['monthly_diff'] = tufe_20['monthly'].diff()\n",
    "tufe_20.loc[11, 'yearly_diff'] = 12.15-11.84\n",
    "tufe_20.loc[11, 'monthly_diff'] = 1.35-0.74\n",
    "tufe_20 = pd.merge(dates20, tufe_20, on=['date'], how='left')\n",
    "tufe_20.fillna(method='ffill', inplace=True)\n",
    "tufe_20.columns = ['tufe_'+i for i in tufe_20.columns]\n",
    "tufe_20['order_week'] = tufe_20['tufe_date'].dt.week\n",
    "tufe_20 = tufe_20.groupby('order_week').min().reset_index().drop(['tufe_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/2252790197.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  ufe_20['order_week'] = ufe_20['ufe_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "ufe_20 = pd.read_excel('data/ufe_20.xlsx', parse_dates=['date'])\n",
    "ufe_20.sort_values(by='date', inplace=True)\n",
    "ufe_20['yearly_diff'] = ufe_20['yearly'].diff()\n",
    "ufe_20['monthly_diff'] = ufe_20['monthly'].diff()\n",
    "ufe_20.loc[11, 'yearly_diff'] = 8.84-7.36\n",
    "ufe_20.loc[11, 'monthly_diff'] = 1.84-0.69\n",
    "ufe_20 = pd.merge(dates20, ufe_20, on=['date'], how='left')\n",
    "ufe_20.fillna(method='ffill', inplace=True)\n",
    "ufe_20.columns = ['ufe_'+i for i in ufe_20.columns]\n",
    "ufe_20['order_week'] = ufe_20['ufe_date'].dt.week\n",
    "ufe_20 = ufe_20.groupby('order_week').min().reset_index().drop(['ufe_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = pd.merge(order_df, currency_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, tufe_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, ufe_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, holidays_20, on=['order_week'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_week', 'material_num', 'customer_num', 'order_amount',\n",
       "       'order_sum2', 'order_sum3', 'order_sum4', 'order_sum5', 'order_sum7',\n",
       "       'order_sum10', 'order_sum14', 'cust_sum2', 'cust_sum3', 'cust_sum4',\n",
       "       'cust_sum5', 'cust_sum7', 'cust_sum10', 'cust_sum14', 'prod_sum2',\n",
       "       'prod_sum3', 'prod_sum4', 'prod_sum5', 'prod_sum7', 'prod_sum10',\n",
       "       'prod_sum14', 'whole_sum2', 'whole_sum3', 'whole_sum4', 'whole_sum5',\n",
       "       'whole_sum7', 'whole_sum10', 'whole_sum14', 'EUR_min', 'EUR_max',\n",
       "       'EUR_avg', 'EUR_std', 'USD_min', 'USD_max', 'USD_avg', 'USD_std',\n",
       "       'USD_diff_1', 'USD_diff_2', 'USD_diff_3', 'USD_diff_5', 'USD_diff_7',\n",
       "       'USD_diff_14', 'EUR_diff_1', 'EUR_diff_2', 'EUR_diff_3', 'EUR_diff_5',\n",
       "       'EUR_diff_7', 'EUR_diff_14', 'tufe_yearly', 'tufe_monthly',\n",
       "       'tufe_yearly_diff', 'tufe_monthly_diff', 'ufe_yearly', 'ufe_monthly',\n",
       "       'ufe_yearly_diff', 'ufe_monthly_diff', 'workday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['order_date', 'order_item', 'order_type', 'operation_type', 'palette_std','order_num']\n",
    "categorical = ['material_num', 'customer_num', 'order_week']\n",
    "numerical = [  'order_sum2', 'order_sum3', 'order_sum4', 'order_sum5', 'order_sum7',\n",
    "               'order_sum10', 'order_sum14', 'cust_sum2', 'cust_sum3', 'cust_sum4',\n",
    "               'cust_sum5', 'cust_sum7', 'cust_sum10', 'cust_sum14', 'prod_sum2',\n",
    "               'prod_sum3', 'prod_sum4', 'prod_sum5', 'prod_sum7', 'prod_sum10',\n",
    "               'prod_sum14', 'whole_sum2', 'whole_sum3', 'whole_sum4', 'whole_sum5',\n",
    "               'whole_sum7', 'whole_sum10', 'whole_sum14', 'EUR_min', 'EUR_max',\n",
    "               'EUR_avg', 'EUR_std', 'USD_min', 'USD_max', 'USD_avg', 'USD_std',\n",
    "               'USD_diff_1', 'USD_diff_2', 'USD_diff_3', 'USD_diff_5', 'USD_diff_7',\n",
    "               'USD_diff_14', 'EUR_diff_1', 'EUR_diff_2', 'EUR_diff_3', 'EUR_diff_5',\n",
    "               'EUR_diff_7', 'EUR_diff_14', 'tufe_yearly', 'tufe_monthly',\n",
    "               'tufe_yearly_diff', 'tufe_monthly_diff', 'ufe_yearly', 'ufe_monthly',\n",
    "               'ufe_yearly_diff', 'ufe_monthly_diff', 'workday']\n",
    "label = ['order_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_defined_columns = drops + categorical + numerical + label\n",
    "if sorted(order_df.columns) != (sorted(all_defined_columns)):\n",
    "    assert('Columns are not equal!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1 - only past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_transofmer():\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[('num', numeric_transformer, numerical),\n",
    "                                                  ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(regressor):\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[('num', numeric_transformer, numerical),\n",
    "                                                  ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 regressor])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df['material_num'] = order_df['material_num'].astype('str')\n",
    "order_df['customer_num'] = order_df['customer_num'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indexes = list(order_df[order_df['order_amount']>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "neg_indexes = random.sample(set(order_df.index).difference(set(pos_indexes)), 3*len(pos_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df = order_df.loc[sorted(neg_indexes+pos_indexes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df[categorical+numerical]\n",
    "y = model_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series split\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Train rmse: 28.783811962023083, r2: 0.8699662132158469\n",
      "Test rmse: 101.84239291364659, r2: 0.016893598890844852\n",
      "-------------\n",
      "Train rmse: 38.24098851428657, r2: 0.8271764540822963\n",
      "Test rmse: 80.94946054754399, r2: -0.08890650486837437\n",
      "-------------\n",
      "Train rmse: 38.86382946076991, r2: 0.8025320224010124\n",
      "Test rmse: 85.1456513309107, r2: -0.01089124994255486\n",
      "-------------\n",
      "Train rmse: 40.57381771740226, r2: 0.7813757636653953\n",
      "Test rmse: 83.03640096722437, r2: 0.04840108322430081\n",
      "-------------\n",
      "Train rmse: 42.68864262431482, r2: 0.7561543504319223\n",
      "Test rmse: 245.96970456855732, r2: 0.07545010563740462\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in ts_cv.split(X):\n",
    "\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    print('-------------')\n",
    "    pipeline = create_pipeline(('regressor', XGBRegressor(gamma = 0.05, learning_rate= 0.1, max_depth=5,\n",
    "                                                     n_estimators= 1000, n_jobs= 8, objective= 'reg:squarederror',\n",
    "                                                     reg_alpha= 0.5, reg_lambda= 1, scale_pos_weight=1, subsample= 1.0)))\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_preds = pipeline.predict(X_train)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "    print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_point = int(X.shape[0]/5*4)\n",
    "X_train = X.loc[:cut_point]\n",
    "y_train = y.loc[:cut_point]\n",
    "X_test = X.loc[cut_point:]\n",
    "y_test = y.loc[cut_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_pipe = create_pipeline_transofmer()\n",
    "X_train = trans_pipe.fit_transform(X_train).toarray()\n",
    "X_test = trans_pipe.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    \n",
    "    model = Sequential([\n",
    "                        Dense(100, activation='relu'),\n",
    "                        Dropout(0.2),\n",
    "                        Dense(100, activation='relu'),\n",
    "                        Dense(1)\n",
    "                        ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27810/27810 - 96s - loss: 6421.6284 - val_loss: 24302.5078 - 96s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "27810/27810 - 94s - loss: 5930.3667 - val_loss: 78284.2891 - 94s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "27810/27810 - 94s - loss: 5643.5220 - val_loss: 255486.7969 - 94s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "27810/27810 - 94s - loss: 5372.8740 - val_loss: 264508.6562 - 94s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "27810/27810 - 94s - loss: 5118.0859 - val_loss: 654233.8750 - 94s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "27810/27810 - 94s - loss: 4924.0981 - val_loss: 1560482.8750 - 94s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "27810/27810 - 94s - loss: 4779.2080 - val_loss: 3479031.5000 - 94s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "27810/27810 - 94s - loss: 4564.7939 - val_loss: 2536055.7500 - 94s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "27810/27810 - 94s - loss: 4488.5034 - val_loss: 6055977.5000 - 94s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "27810/27810 - 94s - loss: 4329.9204 - val_loss: 7434058.0000 - 94s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = model_1()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_4448/3246007245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    \n",
    "    model = Sequential([\n",
    "                        LSTM(50, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1],1)),\n",
    "                        #LSTM(50, return_sequences=True,activation='tanh'),\n",
    "                        #Dropout(0.2),\n",
    "                        #LSTM(50, return_sequences=True,activation='tanh'),\n",
    "                        Dense(1)\n",
    "                        ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1],1)\n",
    "model = model_2()\n",
    "history = model.fit(X_train_3d, y_train, \n",
    "                    epochs=10, batch_size=16, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    train_preds = model.predict(X_train_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2 - use other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series split\n",
    "ts_cv = TimeSeriesSplit(\n",
    "         n_splits=5,  #Number of splits used\n",
    "         gap=0,  #No time needed between sets\n",
    "         max_train_size=None, #Auto train sample size \n",
    "         test_size=None, #Auto test sample size)\n",
    "    \n",
    "all_splits = list(ts_cv.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y, cv):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"],\n",
    "    )\n",
    "    mae = -cv_results[\"test_neg_mean_absolute_error\"]\n",
    "    rmse = -cv_results[\"test_neg_root_mean_squared_error\"]\n",
    "    print(\n",
    "        f\"Mean Absolute Error:     {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "        f\"Root Mean Squared Error: {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", ordinal_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    HistGradientBoostingRegressor(\n",
    "        categorical_features=range(2),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gbrt_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-6, 6, 25)\n",
    "naive_linear_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=MinMaxScaler(),\n",
    "    ),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(naive_linear_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sin and cos transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df = pd.DataFrame(\n",
    "    np.arange(26).reshape(-1, 1),\n",
    "    columns=[\"seasons\"],\n",
    ")\n",
    "seasons_df[\"seasons_sin\"] = sin_transformer(4).fit_transform(seasons_df)[\"seasons\"]\n",
    "seasons_df[\"seasons_cos\"] = cos_transformer(4).fit_transform(seasons_df)[\"seasons\"]\n",
    "seasons_df.plot(x=\"seasons\")_ = plt.title(\"Trigonometric encoding for the 'seasons' feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_cossin_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        (\"seasons_sin\", sin_transformer(4), [\"seasons\"]),\n",
    "        (\"seasons_cos\", cos_transformer(4), [\"seasons\"]),\n",
    "    ],\n",
    "    remainder=MinMaxScaler(),\n",
    ")\n",
    "cyclic_cossin_linear_pipeline = make_pipeline(\n",
    "    cyclic_cossin_transformer,\n",
    "    RidgeCV(alphas=alphas),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(cyclic_cossin_linear_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for transformation from time series to supervised\n",
    "df_supervised = df_diff.drop(['prev_sales'],axis=1)\n",
    "#adding lags\n",
    "for inc in range(1,13):\n",
    "    field_name = 'lag_' + str(inc)\n",
    "    df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "#drop null values\n",
    "df_supervised = df_supervised.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols regression\n",
    "\n",
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1', data=df_supervised)\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### day difference between last order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_order_dates = df.groupby(['customer_num','order_num', 'material_num'])['order_date'].min().reset_index()\n",
    "material_order_dates['shifted_date'] = material_order_dates.groupby(['customer_num','order_num', 'material_num'])['order_date'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last 1,2,3,5,7,10 orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amounts = df.groupby(['customer_num', 'material_num','order_num'])['order_amount'].sum().reset_index()\n",
    "for period in [1,2,3,5,7,10]:\n",
    "    col_name = 'last_' + str(period) + '_period_sum'\n",
    "    order_amounts['rolling_sum'] = order_amounts.groupby(['customer_num', 'material_num'])['order_amount'] \\\n",
    "    .rolling(period, min_periods=period).sum().values\n",
    "    \n",
    "    order_amounts[col_name] = order_amounts.groupby(['customer_num', 'material_num'])['rolling_sum'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amounts.isna().sum()/order_amounts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, order_amounts.drop(['order_amount', 'rolling_sum'], axis=1), on=['customer_num', 'material_num', 'order_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order_item numbers in an order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df.groupby(['order_num'])['order_item'].count().reset_index()\n",
    "item_counts.columns = ['order_num', 'num_order_item']\n",
    "df = pd.merge(df, item_counts, on=['order_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last period averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_2_period_avg'] = df['last_2_period_sum']/2\n",
    "df['last_3_period_avg'] = df['last_3_period_sum']/3\n",
    "df['last_5_period_avg'] = df['last_5_period_sum']/5\n",
    "df['last_7_period_avg'] = df['last_7_period_sum']/7\n",
    "df['last_10_period_avg'] = df['last_10_period_sum']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resample = df.rolling('7D')\n",
    "aggregated_df = weekly_resample.agg(['min', 'mean', 'max', 'std'])\n",
    "aggregated_df.columns = ['_'.join(col).strip() + '_week' for col in \n",
    "                         aggregated_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.sort_values(by=['order_date','order_num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(order_df)):\n",
    "    if order_df.order_num[i] > order_df.order_num[i+1]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "order_summary = order_df.groupby(['order_date'])['order_amount'].sum()\n",
    "adf_result = adfuller(order_summary)\n",
    "print(adf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean encoding for customer and product ??? or did we include that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_target_enc_na = .3343 # default na replacement\n",
    "# Expanding Mean\n",
    "cumsum = all_data.groupby('item_id')['target'].cumsum() - all_data['target']\n",
    "cumcnt = all_data.groupby('item_id')['target'].cumcount()\n",
    "\n",
    "all_data['item_target_enc'] = cumsum/cumcnt\n",
    "all_data['item_target_enc'].fillna(item_target_enc_na,inplace=True)\n",
    "corr = np.corrcoef(all_data['target'].values, all_data['item_target_enc'])[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadece difference Ã¼zerinden featurelar bul\n",
    "\n",
    "    - past data based model\n",
    "        - convert sales to daily basis\n",
    "        - geÃ§miÅŸ 10/20/30/40/50/60/90 gÃ¼n verisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data (Features)\n",
    "X_train = all_data[all_data['date_block_num'] < 33]\n",
    "X_train = X_train.drop(['item_cnt_month'], axis=1)\n",
    "# Valid data (Features)\n",
    "X_valid = all_data[all_data['date_block_num'] == 33]\n",
    "X_valid = X_valid.drop(['item_cnt_month'], axis=1)\n",
    "# Test data (Features)\n",
    "X_test = all_data[all_data['date_block_num'] == 34]\n",
    "X_test = X_test.drop(['item_cnt_month'], axis=1)\n",
    "\n",
    "# Train data (Target values)\n",
    "y_train = all_data[all_data['date_block_num'] < 33]['item_cnt_month']\n",
    "# Valid data (Target values)\n",
    "y_valid = all_data[all_data['date_block_num'] == 33]['item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# lgb hyper-parameters\n",
    "params = {'metric': 'rmse',\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.005,\n",
    "          'feature_fraction': 0.75,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_freq': 5,\n",
    "          'force_col_wise' : True,\n",
    "          'random_state': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['shop_id', 'city', 'item_category_id', 'category', 'month']\n",
    "\n",
    "# lgb train and valid dataset\n",
    "dtrain = lgb.Dataset(X_train, y_train)\n",
    "dvalid = lgb.Dataset(X_valid, y_valid)\n",
    " \n",
    "# Train LightGBM model\n",
    "lgb_model = lgb.train(params=params,\n",
    "                      train_set=dtrain,\n",
    "                      num_boost_round=1500,\n",
    "                      valid_sets=(dtrain, dvalid),\n",
    "                      early_stopping_rounds=150,\n",
    "                      categorical_feature=cat_features,\n",
    "                      verbose_eval=100)      \n",
    "\n",
    "preds = lgb_model.predict(X_test).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction graph for different models\n",
    "\n",
    "#Create teh predicted values:\n",
    "naive_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "naive_linear_predictions = naive_linear_pipeline.predict(X.iloc[test_0])\n",
    "one_hot_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "one_hot_linear_predictions = one_hot_linear_pipeline.predict(X.iloc[test_0])\n",
    "cyclic_cossin_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "cyclic_cossin_linear_predictions = cyclic_cossin_linear_pipeline.predict(X.iloc[test_0])\n",
    "cyclic_spline_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "cyclic_spline_linear_predictions = cyclic_spline_linear_pipeline.predict(X.iloc[test_0])\n",
    "#Change \"_0\" with\"_1\", \"_2\", \"_3\" and \"_4\" for remaining splits\n",
    "#Build the graph:\n",
    "last_days = slice(-100, None)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "fig.suptitle(\"Predictions by linear models\")\n",
    "ax.plot(\n",
    "    y.iloc[test_0].values[last_days], #Change \"_0\" with 1,2,3 and 4\n",
    "    \"x-\",\n",
    "    alpha=0.2,\n",
    "    label=\"Actual absenteeism in hours \",\n",
    "    color=\"black\",\n",
    ")\n",
    "ax.plot(\n",
    "    naive_linear_predictions[last_days], \n",
    "    \"x-\", \n",
    "    label=\"Ordinal time features\"\n",
    ")\n",
    "ax.plot(\n",
    "    cyclic_cossin_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"Trigonometric time features\",\n",
    ")\n",
    "ax.plot(\n",
    "    cyclic_spline_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"Spline-based time features\",\n",
    ")\n",
    "ax.plot(\n",
    "    one_hot_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"One-hot time features\",\n",
    ")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 4), sharey=True)\n",
    "fig.suptitle(\"Non-linear regression models\")\n",
    "predictions = [\n",
    "    cyclic_cossin_linear_predictions,\n",
    "    cyclic_spline_linear_predictions,\n",
    "    one_hot_linear_predictions,\n",
    "]\n",
    "labels = [\n",
    "    \"cyclic_cossin_linear_predictions\",\n",
    "    \"Splines + polynomial kernel\",\n",
    "    \"Gradient Boosted Trees\",\n",
    "]\n",
    "for ax, pred, label in zip(axes, predictions, labels):\n",
    "    ax.scatter(y.iloc[test_0].values, pred, alpha=0.3, label=label)\n",
    "    ax.plot([0, 0.125], [0, 0.125], \"--\", label=\"Perfect model\")\n",
    "    ax.set(\n",
    "           xlim=(0, 0.125),\n",
    "           ylim=(0, 0.125),\n",
    "           xlabel=\"True absenteeism\",\n",
    "           ylabel=\"Predicted absenteeism\",\n",
    "    )\n",
    "    ax.legend()\n",
    "#Change \"test_0\" with _1, _2, _3 or _4 to obtain graphical visualisations for the other splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling non-linear features 1\n",
    "\n",
    "cyclic_spline_poly_pipeline = make_pipeline(\n",
    "    cyclic_spline_transformer,\n",
    "    Nystroem(kernel=\"poly\", degree=2, n_components=300, random_state=0),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")\n",
    "evaluate(cyclic_spline_poly_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling non-linear features 2\n",
    "one_hot_poly_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),         \n",
    "            (\"one_hot_time\", one_hot_encoder, [\"month_of_absence\", \"day_of_the_week\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    Nystroem(kernel=\"poly\", degree=2, n_components=300, random_state=0),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")\n",
    "evaluate(one_hot_poly_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for all customers, all materials and all dates\n",
    "\n",
    "unq_materials = pd.DataFrame(order_df['material_num'].unique(), columns=['material_num'])\n",
    "unq_materials['key'] = 1\n",
    "unq_customers = pd.DataFrame(order_df['customer_num'].unique(), columns=['customer_num'])\n",
    "unq_customers['key'] = 1\n",
    "dates = pd.DataFrame(pd.date_range(start=raw_df['order_date'].min(), end=raw_df['order_date'].max()), columns=['order_date'])\n",
    "dates['key'] = 1\n",
    "all_data = pd.merge(dates, unq_customers, on=['key'])\n",
    "all_data = pd.merge(all_data, unq_materials, on=['key']).drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates21 = pd.DataFrame(pd.date_range(start='01-01-2021', end='30-11-2021'), columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhl_datathon_21",
   "language": "python",
   "name": "dhl_datathon_21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
