{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trials\n",
    "    - sum of past data\n",
    "    - average of past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IsmailKaraman\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "order_df = pd.read_csv('data/order_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28656570, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_week</th>\n",
       "      <th>material_num</th>\n",
       "      <th>customer_num</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_sum2</th>\n",
       "      <th>order_sum3</th>\n",
       "      <th>order_sum4</th>\n",
       "      <th>order_sum5</th>\n",
       "      <th>order_sum7</th>\n",
       "      <th>order_sum10</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_sum7</th>\n",
       "      <th>prod_sum10</th>\n",
       "      <th>prod_sum14</th>\n",
       "      <th>whole_sum2</th>\n",
       "      <th>whole_sum3</th>\n",
       "      <th>whole_sum4</th>\n",
       "      <th>whole_sum5</th>\n",
       "      <th>whole_sum7</th>\n",
       "      <th>whole_sum10</th>\n",
       "      <th>whole_sum14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10140</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10142</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10143</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>91704</td>\n",
       "      <td>M10158</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_week material_num customer_num  order_amount  order_sum2  order_sum3  \\\n",
       "0           1        91704       M10125             2           0           0   \n",
       "1           1        91704       M10140            21           0           0   \n",
       "2           1        91704       M10142            13           0           0   \n",
       "3           1        91704       M10143            12           0           0   \n",
       "4           1        91704       M10158             4           0           0   \n",
       "\n",
       "   order_sum4  order_sum5  order_sum7  order_sum10  ...  prod_sum7  \\\n",
       "0           0           0           0            0  ...          0   \n",
       "1           0           0           0            0  ...          0   \n",
       "2           0           0           0            0  ...          0   \n",
       "3           0           0           0            0  ...          0   \n",
       "4           0           0           0            0  ...          0   \n",
       "\n",
       "   prod_sum10  prod_sum14  whole_sum2  whole_sum3  whole_sum4  whole_sum5  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   whole_sum7  whole_sum10  whole_sum14  \n",
       "0           0            0            0  \n",
       "1           0            0            0  \n",
       "2           0            0            0  \n",
       "3           0            0            0  \n",
       "4           0            0            0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_week       int64\n",
       "material_num    object\n",
       "customer_num    object\n",
       "order_amount     int64\n",
       "order_sum2       int64\n",
       "order_sum3       int64\n",
       "order_sum4       int64\n",
       "order_sum5       int64\n",
       "order_sum7       int64\n",
       "order_sum10      int64\n",
       "order_sum14      int64\n",
       "cust_sum2        int64\n",
       "cust_sum3        int64\n",
       "cust_sum4        int64\n",
       "cust_sum5        int64\n",
       "cust_sum7        int64\n",
       "cust_sum10       int64\n",
       "cust_sum14       int64\n",
       "prod_sum2        int64\n",
       "prod_sum3        int64\n",
       "prod_sum4        int64\n",
       "prod_sum5        int64\n",
       "prod_sum7        int64\n",
       "prod_sum10       int64\n",
       "prod_sum14       int64\n",
       "whole_sum2       int64\n",
       "whole_sum3       int64\n",
       "whole_sum4       int64\n",
       "whole_sum5       int64\n",
       "whole_sum7       int64\n",
       "whole_sum10      int64\n",
       "whole_sum14      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates20 = pd.DataFrame(pd.date_range(start='01-01-2020', end='31-12-2020'), columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/3925827490.py:3: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  currency_20['order_week'] = currency_20['date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "currency_20 = pd.read_csv('data/currency_20.csv', parse_dates=['date'])\n",
    "currency_20.dropna(inplace=True)\n",
    "currency_20['order_week'] = currency_20['date'].dt.week\n",
    "\n",
    "for curr in ['EUR', 'USD']:\n",
    "    for operator in ['min', 'max', 'avg', 'std']:\n",
    "        currency_20[curr + '_' + operator] = currency_20[curr]\n",
    "        \n",
    "currency_20 = currency_20.groupby('order_week').agg({'EUR_min':'min', 'EUR_max':'max', 'EUR_avg':'mean', 'EUR_std':'std', \n",
    "                                               'USD_min':'min', 'USD_max':'max', 'USD_avg':'mean', 'USD_std':'std'}).reset_index()    \n",
    "\n",
    "currency_20['USD_diff_1'] = currency_20['USD_avg'].diff(1)\n",
    "currency_20['USD_diff_2'] = currency_20['USD_avg'].diff(2)\n",
    "currency_20['USD_diff_3'] = currency_20['USD_avg'].diff(3)\n",
    "currency_20['USD_diff_5'] = currency_20['USD_avg'].diff(5)\n",
    "currency_20['USD_diff_7'] = currency_20['USD_avg'].diff(7)\n",
    "currency_20['USD_diff_14'] = currency_20['USD_avg'].diff(14)\n",
    "\n",
    "currency_20['EUR_diff_1'] = currency_20['EUR_avg'].diff(1)\n",
    "currency_20['EUR_diff_2'] = currency_20['EUR_avg'].diff(2)\n",
    "currency_20['EUR_diff_3'] = currency_20['EUR_avg'].diff(3)\n",
    "currency_20['EUR_diff_5'] = currency_20['EUR_avg'].diff(5)\n",
    "currency_20['EUR_diff_7'] = currency_20['EUR_avg'].diff(7)\n",
    "currency_20['EUR_diff_14'] = currency_20['EUR_avg'].diff(14)\n",
    "currency_20.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/1395646822.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  holidays_20['order_week'] = holidays_20['date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "holidays_20 = pd.read_excel('data/holidays_20.xlsx', parse_dates=['date'])\n",
    "holidays_20 = pd.merge(dates20, holidays_20, on=['date'], how='left')\n",
    "holidays_20.fillna(1.0, inplace=True)\n",
    "holidays_20['order_week'] = holidays_20['date'].dt.week\n",
    "holidays_20 = holidays_20.groupby('order_week')['workday'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/3738567944.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  tufe_20['order_week'] = tufe_20['tufe_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "tufe_20 = pd.read_excel('data/tufe_20.xlsx', parse_dates=['date'])\n",
    "tufe_20.sort_values(by='date', inplace=True)\n",
    "tufe_20['yearly_diff'] = tufe_20['yearly'].diff()\n",
    "tufe_20['monthly_diff'] = tufe_20['monthly'].diff()\n",
    "tufe_20.loc[11, 'yearly_diff'] = 12.15-11.84\n",
    "tufe_20.loc[11, 'monthly_diff'] = 1.35-0.74\n",
    "tufe_20 = pd.merge(dates20, tufe_20, on=['date'], how='left')\n",
    "tufe_20.fillna(method='ffill', inplace=True)\n",
    "tufe_20.columns = ['tufe_'+i for i in tufe_20.columns]\n",
    "tufe_20['order_week'] = tufe_20['tufe_date'].dt.week\n",
    "tufe_20 = tufe_20.groupby('order_week').min().reset_index().drop(['tufe_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/2252790197.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  ufe_20['order_week'] = ufe_20['ufe_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "ufe_20 = pd.read_excel('data/ufe_20.xlsx', parse_dates=['date'])\n",
    "ufe_20.sort_values(by='date', inplace=True)\n",
    "ufe_20['yearly_diff'] = ufe_20['yearly'].diff()\n",
    "ufe_20['monthly_diff'] = ufe_20['monthly'].diff()\n",
    "ufe_20.loc[11, 'yearly_diff'] = 8.84-7.36\n",
    "ufe_20.loc[11, 'monthly_diff'] = 1.84-0.69\n",
    "ufe_20 = pd.merge(dates20, ufe_20, on=['date'], how='left')\n",
    "ufe_20.fillna(method='ffill', inplace=True)\n",
    "ufe_20.columns = ['ufe_'+i for i in ufe_20.columns]\n",
    "ufe_20['order_week'] = ufe_20['ufe_date'].dt.week\n",
    "ufe_20 = ufe_20.groupby('order_week').min().reset_index().drop(['ufe_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = pd.merge(order_df, currency_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, tufe_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, ufe_20, on=['order_week'], how='left')\n",
    "order_df = pd.merge(order_df, holidays_20, on=['order_week'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_week', 'material_num', 'customer_num', 'order_amount',\n",
       "       'order_sum2', 'order_sum3', 'order_sum4', 'order_sum5', 'order_sum7',\n",
       "       'order_sum10', 'order_sum14', 'cust_sum2', 'cust_sum3', 'cust_sum4',\n",
       "       'cust_sum5', 'cust_sum7', 'cust_sum10', 'cust_sum14', 'prod_sum2',\n",
       "       'prod_sum3', 'prod_sum4', 'prod_sum5', 'prod_sum7', 'prod_sum10',\n",
       "       'prod_sum14', 'whole_sum2', 'whole_sum3', 'whole_sum4', 'whole_sum5',\n",
       "       'whole_sum7', 'whole_sum10', 'whole_sum14', 'EUR_min', 'EUR_max',\n",
       "       'EUR_avg', 'EUR_std', 'USD_min', 'USD_max', 'USD_avg', 'USD_std',\n",
       "       'USD_diff_1', 'USD_diff_2', 'USD_diff_3', 'USD_diff_5', 'USD_diff_7',\n",
       "       'USD_diff_14', 'EUR_diff_1', 'EUR_diff_2', 'EUR_diff_3', 'EUR_diff_5',\n",
       "       'EUR_diff_7', 'EUR_diff_14', 'tufe_yearly', 'tufe_monthly',\n",
       "       'tufe_yearly_diff', 'tufe_monthly_diff', 'ufe_yearly', 'ufe_monthly',\n",
       "       'ufe_yearly_diff', 'ufe_monthly_diff', 'workday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['order_date', 'order_item', 'order_type', 'operation_type', 'palette_std','order_num']\n",
    "categorical = ['material_num', 'customer_num', 'order_week']\n",
    "numerical = [  'order_sum2', 'order_sum3', 'order_sum4', 'order_sum5', 'order_sum7',\n",
    "               'order_sum10', 'order_sum14', 'cust_sum2', 'cust_sum3', 'cust_sum4',\n",
    "               'cust_sum5', 'cust_sum7', 'cust_sum10', 'cust_sum14', 'prod_sum2',\n",
    "               'prod_sum3', 'prod_sum4', 'prod_sum5', 'prod_sum7', 'prod_sum10',\n",
    "               'prod_sum14', 'whole_sum2', 'whole_sum3', 'whole_sum4', 'whole_sum5',\n",
    "               'whole_sum7', 'whole_sum10', 'whole_sum14', 'EUR_min', 'EUR_max',\n",
    "               'EUR_avg', 'EUR_std', 'USD_min', 'USD_max', 'USD_avg', 'USD_std',\n",
    "               'USD_diff_1', 'USD_diff_2', 'USD_diff_3', 'USD_diff_5', 'USD_diff_7',\n",
    "               'USD_diff_14', 'EUR_diff_1', 'EUR_diff_2', 'EUR_diff_3', 'EUR_diff_5',\n",
    "               'EUR_diff_7', 'EUR_diff_14', 'tufe_yearly', 'tufe_monthly',\n",
    "               'tufe_yearly_diff', 'tufe_monthly_diff', 'ufe_yearly', 'ufe_monthly',\n",
    "               'ufe_yearly_diff', 'ufe_monthly_diff', 'workday']\n",
    "label = ['order_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_defined_columns = drops + categorical + numerical + label\n",
    "if sorted(order_df.columns) != (sorted(all_defined_columns)):\n",
    "    assert('Columns are not equal!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1 - only past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_transofmer():\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[('num', numeric_transformer, numerical),\n",
    "                                                  ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(regressor):\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[('num', numeric_transformer, numerical),\n",
    "                                                  ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 regressor])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df['material_num'] = order_df['material_num'].astype('str')\n",
    "order_df['customer_num'] = order_df['customer_num'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indexes = list(order_df[order_df['order_amount']>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "neg_indexes = random.sample(set(order_df.index).difference(set(pos_indexes)), 3*len(pos_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df = order_df.loc[sorted(neg_indexes+pos_indexes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df[categorical+numerical]\n",
    "y = model_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series split\n",
    "ts_cv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Train rmse: 29.45094317420417, r2: 0.8639049902101628\n",
      "Test rmse: 102.28491541300308, r2: 0.008174222494082617\n",
      "-------------\n",
      "Train rmse: 38.317717793057675, r2: 0.8264822126870726\n",
      "Test rmse: 80.78080033696627, r2: -0.08431781929230109\n",
      "-------------\n",
      "Train rmse: 39.19151313589744, r2: 0.799190545996808\n",
      "Test rmse: 83.8319855308735, r2: 0.020022306952609203\n",
      "-------------\n",
      "Train rmse: 40.961392240181766, r2: 0.7771792198890954\n",
      "Test rmse: 82.89823939826105, r2: 0.05155876166963502\n",
      "-------------\n",
      "Train rmse: 41.94585762568174, r2: 0.7645662208392702\n",
      "Test rmse: 243.73243301646022, r2: 0.09219294184832627\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in ts_cv.split(X):\n",
    "\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    print('-------------')\n",
    "    pipeline = create_pipeline(('regressor', XGBRegressor(gamma = 0.05, learning_rate= 0.1, max_depth=5,\n",
    "                                                     n_estimators= 1000, n_jobs= 8, objective= 'reg:squarederror',\n",
    "                                                     reg_alpha= 0.5, reg_lambda= 1, scale_pos_weight=1, subsample= 1.0)))\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_preds = pipeline.predict(X_train)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "    print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_point = int(X.shape[0]/5*4)\n",
    "X_train = X.loc[:cut_point]\n",
    "y_train = y.loc[:cut_point]\n",
    "X_test = X.loc[cut_point:]\n",
    "y_test = y.loc[cut_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_pipe = create_pipeline_transofmer()\n",
    "X_train = trans_pipe.fit_transform(X_train).toarray()\n",
    "X_test = trans_pipe.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    \n",
    "    model = Sequential([\n",
    "                        Dense(100, activation='relu'),\n",
    "                        Dropout(0.2),\n",
    "                        Dense(100, activation='relu'),\n",
    "                        Dense(1)\n",
    "                        ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27810/27810 - 94s - loss: 6404.8511 - val_loss: 17009.9941 - 94s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "27810/27810 - 94s - loss: 5949.0044 - val_loss: 35151.4844 - 94s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "27810/27810 - 92s - loss: 5690.3325 - val_loss: 256604.3281 - 92s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "27810/27810 - 92s - loss: 5427.5654 - val_loss: 647440.3750 - 92s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "27810/27810 - 93s - loss: 5142.7295 - val_loss: 731431.3125 - 93s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "27810/27810 - 93s - loss: 4975.2573 - val_loss: 1192718.8750 - 93s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "27810/27810 - 94s - loss: 4831.2480 - val_loss: 3819381.0000 - 94s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "27810/27810 - 94s - loss: 4609.6631 - val_loss: 5024185.5000 - 94s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "27810/27810 - 93s - loss: 4484.6782 - val_loss: 6767784.0000 - 93s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "27810/27810 - 93s - loss: 4485.2095 - val_loss: 9765438.0000 - 93s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = model_1()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_16028/3246007245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\GitHub\\dhl_datathon_21\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    \n",
    "    model = Sequential([\n",
    "                        LSTM(50, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1],1)),\n",
    "                        #LSTM(50, return_sequences=True,activation='tanh'),\n",
    "                        #Dropout(0.2),\n",
    "                        #LSTM(50, return_sequences=True,activation='tanh'),\n",
    "                        Dense(1)\n",
    "                        ])\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55619/55619 - 2042s - loss: 7637.1660 - val_loss: 7218.1206 - 2042s/epoch - 37ms/step\n",
      "Epoch 2/10\n",
      "55619/55619 - 1986s - loss: 7619.6094 - val_loss: 7234.9775 - 1986s/epoch - 36ms/step\n",
      "Epoch 3/10\n",
      "55619/55619 - 2016s - loss: 7544.0098 - val_loss: 6935.0830 - 2016s/epoch - 36ms/step\n",
      "Epoch 4/10\n",
      "55619/55619 - 2009s - loss: 7293.9556 - val_loss: 6842.3550 - 2009s/epoch - 36ms/step\n",
      "Epoch 5/10\n",
      "55619/55619 - 2014s - loss: 7177.1821 - val_loss: 6846.8945 - 2014s/epoch - 36ms/step\n",
      "Epoch 6/10\n",
      "55619/55619 - 1991s - loss: 7090.9756 - val_loss: 6633.5908 - 1991s/epoch - 36ms/step\n",
      "Epoch 7/10\n",
      "55619/55619 - 1988s - loss: 7093.3267 - val_loss: 6542.0205 - 1988s/epoch - 36ms/step\n",
      "Epoch 8/10\n",
      "55619/55619 - 1991s - loss: 6810.5635 - val_loss: 6464.4360 - 1991s/epoch - 36ms/step\n",
      "Epoch 9/10\n"
     ]
    }
   ],
   "source": [
    "X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1],1)\n",
    "model = model_2()\n",
    "history = model.fit(X_train_3d, y_train, \n",
    "                    epochs=10, batch_size=16, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    train_preds = model.predict(X_train_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train rmse: {mean_squared_error(y_train, train_preds, squared=False)}, r2: {r2_score(y_train, train_preds)}')\n",
    "print(f'Test rmse: {mean_squared_error(y_test, test_preds, squared=False)}, r2: {r2_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=80, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split = 0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2 - use other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series split\n",
    "ts_cv = TimeSeriesSplit(\n",
    "         n_splits=5,  #Number of splits used\n",
    "         gap=0,  #No time needed between sets\n",
    "         max_train_size=None, #Auto train sample size \n",
    "         test_size=None, #Auto test sample size)\n",
    "    \n",
    "all_splits = list(ts_cv.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y, cv):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"],\n",
    "    )\n",
    "    mae = -cv_results[\"test_neg_mean_absolute_error\"]\n",
    "    rmse = -cv_results[\"test_neg_root_mean_squared_error\"]\n",
    "    print(\n",
    "        f\"Mean Absolute Error:     {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "        f\"Root Mean Squared Error: {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", ordinal_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    HistGradientBoostingRegressor(\n",
    "        categorical_features=range(2),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gbrt_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-6, 6, 25)\n",
    "naive_linear_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=MinMaxScaler(),\n",
    "    ),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(naive_linear_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sin and cos transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df = pd.DataFrame(\n",
    "    np.arange(26).reshape(-1, 1),\n",
    "    columns=[\"seasons\"],\n",
    ")\n",
    "seasons_df[\"seasons_sin\"] = sin_transformer(4).fit_transform(seasons_df)[\"seasons\"]\n",
    "seasons_df[\"seasons_cos\"] = cos_transformer(4).fit_transform(seasons_df)[\"seasons\"]\n",
    "seasons_df.plot(x=\"seasons\")_ = plt.title(\"Trigonometric encoding for the 'seasons' feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_cossin_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        (\"seasons_sin\", sin_transformer(4), [\"seasons\"]),\n",
    "        (\"seasons_cos\", cos_transformer(4), [\"seasons\"]),\n",
    "    ],\n",
    "    remainder=MinMaxScaler(),\n",
    ")\n",
    "cyclic_cossin_linear_pipeline = make_pipeline(\n",
    "    cyclic_cossin_transformer,\n",
    "    RidgeCV(alphas=alphas),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(cyclic_cossin_linear_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for transformation from time series to supervised\n",
    "df_supervised = df_diff.drop(['prev_sales'],axis=1)\n",
    "#adding lags\n",
    "for inc in range(1,13):\n",
    "    field_name = 'lag_' + str(inc)\n",
    "    df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "#drop null values\n",
    "df_supervised = df_supervised.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols regression\n",
    "\n",
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1', data=df_supervised)\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### day difference between last order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_order_dates = df.groupby(['customer_num','order_num', 'material_num'])['order_date'].min().reset_index()\n",
    "material_order_dates['shifted_date'] = material_order_dates.groupby(['customer_num','order_num', 'material_num'])['order_date'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last 1,2,3,5,7,10 orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amounts = df.groupby(['customer_num', 'material_num','order_num'])['order_amount'].sum().reset_index()\n",
    "for period in [1,2,3,5,7,10]:\n",
    "    col_name = 'last_' + str(period) + '_period_sum'\n",
    "    order_amounts['rolling_sum'] = order_amounts.groupby(['customer_num', 'material_num'])['order_amount'] \\\n",
    "    .rolling(period, min_periods=period).sum().values\n",
    "    \n",
    "    order_amounts[col_name] = order_amounts.groupby(['customer_num', 'material_num'])['rolling_sum'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_amounts.isna().sum()/order_amounts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, order_amounts.drop(['order_amount', 'rolling_sum'], axis=1), on=['customer_num', 'material_num', 'order_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order_item numbers in an order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df.groupby(['order_num'])['order_item'].count().reset_index()\n",
    "item_counts.columns = ['order_num', 'num_order_item']\n",
    "df = pd.merge(df, item_counts, on=['order_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last period averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_2_period_avg'] = df['last_2_period_sum']/2\n",
    "df['last_3_period_avg'] = df['last_3_period_sum']/3\n",
    "df['last_5_period_avg'] = df['last_5_period_sum']/5\n",
    "df['last_7_period_avg'] = df['last_7_period_sum']/7\n",
    "df['last_10_period_avg'] = df['last_10_period_sum']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resample = df.rolling('7D')\n",
    "aggregated_df = weekly_resample.agg(['min', 'mean', 'max', 'std'])\n",
    "aggregated_df.columns = ['_'.join(col).strip() + '_week' for col in \n",
    "                         aggregated_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.sort_values(by=['order_date','order_num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(order_df)):\n",
    "    if order_df.order_num[i] > order_df.order_num[i+1]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "order_summary = order_df.groupby(['order_date'])['order_amount'].sum()\n",
    "adf_result = adfuller(order_summary)\n",
    "print(adf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean encoding for customer and product ??? or did we include that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_target_enc_na = .3343 # default na replacement\n",
    "# Expanding Mean\n",
    "cumsum = all_data.groupby('item_id')['target'].cumsum() - all_data['target']\n",
    "cumcnt = all_data.groupby('item_id')['target'].cumcount()\n",
    "\n",
    "all_data['item_target_enc'] = cumsum/cumcnt\n",
    "all_data['item_target_enc'].fillna(item_target_enc_na,inplace=True)\n",
    "corr = np.corrcoef(all_data['target'].values, all_data['item_target_enc'])[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadece difference Ã¼zerinden featurelar bul\n",
    "\n",
    "    - past data based model\n",
    "        - convert sales to daily basis\n",
    "        - geÃ§miÅŸ 10/20/30/40/50/60/90 gÃ¼n verisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data (Features)\n",
    "X_train = all_data[all_data['date_block_num'] < 33]\n",
    "X_train = X_train.drop(['item_cnt_month'], axis=1)\n",
    "# Valid data (Features)\n",
    "X_valid = all_data[all_data['date_block_num'] == 33]\n",
    "X_valid = X_valid.drop(['item_cnt_month'], axis=1)\n",
    "# Test data (Features)\n",
    "X_test = all_data[all_data['date_block_num'] == 34]\n",
    "X_test = X_test.drop(['item_cnt_month'], axis=1)\n",
    "\n",
    "# Train data (Target values)\n",
    "y_train = all_data[all_data['date_block_num'] < 33]['item_cnt_month']\n",
    "# Valid data (Target values)\n",
    "y_valid = all_data[all_data['date_block_num'] == 33]['item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# lgb hyper-parameters\n",
    "params = {'metric': 'rmse',\n",
    "          'num_leaves': 255,\n",
    "          'learning_rate': 0.005,\n",
    "          'feature_fraction': 0.75,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_freq': 5,\n",
    "          'force_col_wise' : True,\n",
    "          'random_state': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['shop_id', 'city', 'item_category_id', 'category', 'month']\n",
    "\n",
    "# lgb train and valid dataset\n",
    "dtrain = lgb.Dataset(X_train, y_train)\n",
    "dvalid = lgb.Dataset(X_valid, y_valid)\n",
    " \n",
    "# Train LightGBM model\n",
    "lgb_model = lgb.train(params=params,\n",
    "                      train_set=dtrain,\n",
    "                      num_boost_round=1500,\n",
    "                      valid_sets=(dtrain, dvalid),\n",
    "                      early_stopping_rounds=150,\n",
    "                      categorical_feature=cat_features,\n",
    "                      verbose_eval=100)      \n",
    "\n",
    "preds = lgb_model.predict(X_test).clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction graph for different models\n",
    "\n",
    "#Create teh predicted values:\n",
    "naive_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "naive_linear_predictions = naive_linear_pipeline.predict(X.iloc[test_0])\n",
    "one_hot_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "one_hot_linear_predictions = one_hot_linear_pipeline.predict(X.iloc[test_0])\n",
    "cyclic_cossin_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "cyclic_cossin_linear_predictions = cyclic_cossin_linear_pipeline.predict(X.iloc[test_0])\n",
    "cyclic_spline_linear_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "cyclic_spline_linear_predictions = cyclic_spline_linear_pipeline.predict(X.iloc[test_0])\n",
    "#Change \"_0\" with\"_1\", \"_2\", \"_3\" and \"_4\" for remaining splits\n",
    "#Build the graph:\n",
    "last_days = slice(-100, None)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "fig.suptitle(\"Predictions by linear models\")\n",
    "ax.plot(\n",
    "    y.iloc[test_0].values[last_days], #Change \"_0\" with 1,2,3 and 4\n",
    "    \"x-\",\n",
    "    alpha=0.2,\n",
    "    label=\"Actual absenteeism in hours \",\n",
    "    color=\"black\",\n",
    ")\n",
    "ax.plot(\n",
    "    naive_linear_predictions[last_days], \n",
    "    \"x-\", \n",
    "    label=\"Ordinal time features\"\n",
    ")\n",
    "ax.plot(\n",
    "    cyclic_cossin_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"Trigonometric time features\",\n",
    ")\n",
    "ax.plot(\n",
    "    cyclic_spline_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"Spline-based time features\",\n",
    ")\n",
    "ax.plot(\n",
    "    one_hot_linear_predictions[last_days],\n",
    "    \"x-\",\n",
    "    label=\"One-hot time features\",\n",
    ")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 4), sharey=True)\n",
    "fig.suptitle(\"Non-linear regression models\")\n",
    "predictions = [\n",
    "    cyclic_cossin_linear_predictions,\n",
    "    cyclic_spline_linear_predictions,\n",
    "    one_hot_linear_predictions,\n",
    "]\n",
    "labels = [\n",
    "    \"cyclic_cossin_linear_predictions\",\n",
    "    \"Splines + polynomial kernel\",\n",
    "    \"Gradient Boosted Trees\",\n",
    "]\n",
    "for ax, pred, label in zip(axes, predictions, labels):\n",
    "    ax.scatter(y.iloc[test_0].values, pred, alpha=0.3, label=label)\n",
    "    ax.plot([0, 0.125], [0, 0.125], \"--\", label=\"Perfect model\")\n",
    "    ax.set(\n",
    "           xlim=(0, 0.125),\n",
    "           ylim=(0, 0.125),\n",
    "           xlabel=\"True absenteeism\",\n",
    "           ylabel=\"Predicted absenteeism\",\n",
    "    )\n",
    "    ax.legend()\n",
    "#Change \"test_0\" with _1, _2, _3 or _4 to obtain graphical visualisations for the other splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling non-linear features 1\n",
    "\n",
    "cyclic_spline_poly_pipeline = make_pipeline(\n",
    "    cyclic_spline_transformer,\n",
    "    Nystroem(kernel=\"poly\", degree=2, n_components=300, random_state=0),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")\n",
    "evaluate(cyclic_spline_poly_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling non-linear features 2\n",
    "one_hot_poly_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),         \n",
    "            (\"one_hot_time\", one_hot_encoder, [\"month_of_absence\", \"day_of_the_week\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    Nystroem(kernel=\"poly\", degree=2, n_components=300, random_state=0),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")\n",
    "evaluate(one_hot_poly_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for all customers, all materials and all dates\n",
    "\n",
    "unq_materials = pd.DataFrame(order_df['material_num'].unique(), columns=['material_num'])\n",
    "unq_materials['key'] = 1\n",
    "unq_customers = pd.DataFrame(order_df['customer_num'].unique(), columns=['customer_num'])\n",
    "unq_customers['key'] = 1\n",
    "dates = pd.DataFrame(pd.date_range(start=raw_df['order_date'].min(), end=raw_df['order_date'].max()), columns=['order_date'])\n",
    "dates['key'] = 1\n",
    "all_data = pd.merge(dates, unq_customers, on=['key'])\n",
    "all_data = pd.merge(all_data, unq_materials, on=['key']).drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates21 = pd.DataFrame(pd.date_range(start='01-01-2021', end='30-11-2021'), columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhl_datathon_21",
   "language": "python",
   "name": "dhl_datathon_21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
